{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429c6da8-62af-411b-9707-f1c8eeaceeae",
   "metadata": {},
   "source": [
    "# T√†i li·ªáu Ven3 Docs v√† Image Preview 2D-3D\n",
    "\n",
    "_https://ai.google.dev/gemini-api/docs/models_\n",
    "\n",
    "_https://ai.google.dev/gemini-api/docs/prompting-strategies_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb34e64-d497-4e0e-a6d8-7da11946d7f6",
   "metadata": {},
   "source": [
    "# T·∫£i Video, Audio, Ph·ª• ƒë·ªÅ En, Vi:\n",
    "## Tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ t·ª´ YouTube:\n",
    ">> Trong c√°c video Youtube v·ªÅ d·ª± √°n Fine-Tune LLMs, t√¥i mu·ªën d√πng python 3.11 vi·∫øt code python jupyter notebook s·ª≠ d·ª•ng models nh∆∞ YOLO ƒë·ªÉ c√≥ th·ªÉ b√≥c t√°ch [Object Text] c√°c ph·ª• ƒë·ªÅ ti·∫øng Anh ho·∫∑c ti·∫øng Vi·ªát t·ª´ c√°c URL youtube nh∆∞: https://www.youtube.com/watch?v=A9g4ZkJrcoA&t=2972s , L·∫•y ra ƒë∆∞·ª£c script string v√† d√πng ti·∫øp AI Drawio ƒë·ªÉ l·∫≠p th√†nh b·∫£n v·∫Ω s∆° ƒë·ªì, v·∫Ω c√°c b∆∞·ªõc quy tr√¨nh th·ª±c hi·ªán step by step, h√£y gi√∫p t√¥i vi·∫øt code python n√†y\n",
    "\n",
    ">>> H∆∞·ªõng d·∫´n t√¥i d√πng code python 3.11 vi·∫øt ƒëo·∫°n m√£ download video mp4 720HD/1080 HD, audio mp3 v√† caption srt t·ª´ youtube.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d083c9c-f3db-4c67-b549-a80efa9d5a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytube\n",
    "!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "!pip install youtube-dlg\n",
    "!pip install youtube-dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0fa54-c526-4f72-83e2-3e6601404fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "download_dir = './videoytb/'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# URL video YouTube\n",
    "video_url = \\\\\\\"https://www.youtube.com/watch?v=lqKapMX2GAI\\\\\\\"\n",
    "\n",
    "# C·∫•u h√¨nh t·∫£i\n",
    "ydl_opts = {\n",
    "    'format': 'bestvideo+bestaudio',                    # T·∫£i video v√† audio ri√™ng bi·ªát\n",
    "    'outtmpl': download_dir + '%(title)s.%(ext)s',      # L∆∞u v√†o th∆∞ m·ª•c ./videoytb/\n",
    "    'writesubtitles': True,                             # T·∫£i ph·ª• ƒë·ªÅ\n",
    "    'writeautomaticsub': True,                          # T·∫£i ph·ª• ƒë·ªÅ t·ª± ƒë·ªông n·∫øu kh√¥ng c√≥ ph·ª• ƒë·ªÅ g·ªëc\n",
    "    'subtitlesformat': 'srt',                           # ƒê·ªãnh d·∫°ng ph·ª• ƒë·ªÅ .srt\n",
    "    'subtitleslangs': ['en', 'vi'],                     # T·∫£i c·∫£ ph·ª• ƒë·ªÅ ti·∫øng Anh v√† ti·∫øng Vi·ªát\n",
    "#    'merge_output_format': 'mp4',                        # ƒê·∫£m b·∫£o video c√≥ h√¨nh v√† ti·∫øng\n",
    "    'postprocessors': [\n",
    "        {\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "            'nopostoverwrites': False\n",
    "        }\n",
    "    ],\n",
    "    'keepvideo': True                                   # Gi·ªØ file video ri√™ng bi·ªát, kh√¥ng merge\n",
    "}\n",
    "\n",
    "# T·∫£i video/audio/ph·ª• ƒë·ªÅ\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([video_url])\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c9a48-4289-4679-bef9-715e7f5c5f1d",
   "metadata": {},
   "source": [
    "# X·ª≠ l√Ω vƒÉn b·∫£n\n",
    "L∆∞u ph·ª• ƒë·ªÅ d∆∞·ªõi d·∫°ng script string ƒë·ªÉ s·ª≠ d·ª•ng cho AI Draw.io..\n",
    "\n",
    "# T·∫°o s∆° ƒë·ªì quy tr√¨nh\n",
    "D√πng AI Draw.io ƒë·ªÉ chuy·ªÉn n·ªôi dung th√†nh s∆° ƒë·ªì tr·ª±c quan.\n",
    "\n",
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "Tr∆∞·ªõc ti√™n, h√£y c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán h·ªó tr·ª£:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cba5d3-542a-4f8e-882b-04c5de1f6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api drawio pandas\\\"\n",
    "\n",
    " from youtube_transcript_api import YouTubeTranscriptApi\n",
    " import pandas as pd\n",
    " \n",
    " # URL video YouTube\n",
    " video_url = \\\\\\\"https://www.youtube.com/watch?v=_KoifHHJhNY\\\\\\\"\n",
    " \n",
    " # L·∫•y ID video t·ª´ URL\n",
    " video_id = video_url.split(\\\\\\\"v=\\\\\\\")[-1].split(\\\\\\\"&\\\\\\\")[0]\n",
    " \n",
    " # L·∫•y ph·ª• ƒë·ªÅ (ti·∫øng Anh ho·∫∑c ti·∫øng Vi·ªát)\n",
    " transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'vi'])\n",
    " \n",
    " # Chuy·ªÉn ph·ª• ƒë·ªÅ th√†nh script string\n",
    " script_text = \\\\\\\"\\\\\\\\n\\\\\\\".join([segment['text'] for segment in transcript])\n",
    " \n",
    " # L∆∞u v√†o file CSV\n",
    " df = pd.DataFrame(transcript)\n",
    " df.to_csv(r\\\\\\\"C:\\\\\\\\Python311\\\\\\\\ytb-api\\\\\\\\YOLO_Ultralytics.csv\\\\\\\", index=False)\n",
    " \n",
    " print(\\\\\\\"Ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c tr√≠ch xu·∫•t th√†nh c√¥ng!\\\\\\\")\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d305e-a331-4a7b-96ec-fd0e660bffa5",
   "metadata": {},
   "source": [
    "# Chuy·ªÉn vƒÉn b·∫£n th√†nh s∆° ƒë·ªì Draw.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb6187-34fb-4185-a631-101215d3c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diagrams\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca0d22-9de9-4fcf-b805-d891c0d9ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Diagram\n",
    "from diagrams.generic.blank import Blank\n",
    "\n",
    "with Diagram(\\\\\\\"Workflow Diagram\\\\\\\", show=False, filename=\\\\\\\"workflow\\\\\\\"):\n",
    "    Blank(\\\\\\\"Step 1\\\\\\\")\n",
    "    Blank(\\\\\\\"Step 2\\\\\\\")\n",
    "    Blank(\\\\\\\"Step 3\\\\\\\")\n",
    "\n",
    "# Load file vƒÉn b·∫£n ƒë√£ tr√≠ch xu·∫•t\n",
    "df = pd.read_csv(r\\\\\\\"C:\\\\\\\\Python311\\\\\\\\ytb-api\\\\\\\\youtube_subtitles.en.csv\\\\\\\")\n",
    "\n",
    "# Kh·ªüi t·∫°o s∆° ƒë·ªì\n",
    "diagram = DrawioDiagram(\\\\\\\"C:\\\\\\\\Python311\\\\\\\\ytb-api\\\\\\\\workflow.xml\\\\\\\")\n",
    "\n",
    "# Th√™m c√°c b∆∞·ªõc t·ª´ script\n",
    "for index, row in df.iterrows():\n",
    "    diagram.add_shape(row[\\\\\\\"Text\\\\\\\"], x=index*150, y=100)\n",
    "\n",
    "# L∆∞u s∆° ƒë·ªì d∆∞·ªõi d·∫°ng file Draw.io\n",
    "diagram.save()\n",
    "\n",
    "print(\\\\\\\"S∆° ƒë·ªì quy tr√¨nh ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!\\\\\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996555c7-aa07-4945-9ed8-6c9ebffa79bc",
   "metadata": {},
   "source": [
    "# Trong python 3.11 tr√™n windows 11 pro c√≥ open-webui v√† ollama 3.2:1b t√¥i c·∫ßn vi·∫øt code python sao cho c√≥ th·ªÉ load file mp4 video m√† c√≥ th·ªÉ chuy·ªÉn ƒëo·∫°n audio c√≥ ti·∫øng th√†nh file ph·ª• ƒë·ªÉ srt ki·ªÉu speech to text (kh√¥ng t√°ch file ti·∫øng audio)?\n",
    " \n",
    " M√£ Python ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ:\n",
    " \n",
    " - **X·ª≠ l√Ω tr·ª±c ti·∫øp file MP4** m√† kh√¥ng c·∫ßn t√°ch audio ri√™ng.\n",
    " - **Tr√≠ch xu·∫•t audio t·∫°m th·ªùi**, chuy·ªÉn th√†nh vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh **Whisper**.\n",
    " - **T·∫°o file ph·ª• ƒë·ªÅ `.srt`** v·ªõi th·ªùi gian hi·ªÉn th·ªã ch√≠nh x√°c.\n",
    " \n",
    " Tuy nhi√™n, h·ªá th·ªëng hi·ªán t·∫°i ch∆∞a c√†i s·∫µn th∆∞ vi·ªán `whisper`, n√™n kh√¥ng th·ªÉ ch·∫°y tr·ª±c ti·∫øp. Anh c√≥ th·ªÉ c√†i tr√™n m√°y Windows 11 Pro c·ªßa m√¨nh b·∫±ng l·ªánh:\n",
    " \n",
    " ```bash\n",
    " pip install -U openai-whisper\n",
    " ```\n",
    " \n",
    " ### ‚úÖ G·ª£i √Ω c·∫•u h√¨nh m√¥i tr∆∞·ªùng:\n",
    " - Python 3.11\n",
    " - Windows 11 Pro\n",
    " - ƒê√£ c√†i `ffmpeg` (b·∫Øt bu·ªôc cho x·ª≠ l√Ω video/audio)\n",
    " - C√†i th√™m:\n",
    "   ```bash\n",
    "   pip install moviepy openai-whisper\n",
    "   ```\n",
    " \n",
    " ### üìÑ File m√£ Python ho√†n ch·ªânh\n",
    " Anh c√≥ mu·ªën m√¨nh t·∫°o file `.py` ƒë·ªÉ anh t·∫£i v·ªÅ v√† ch·∫°y tr·ª±c ti·∫øp kh√¥ng?\n",
    " \n",
    " ### T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ (n·∫øu d√πng Whisper)\n",
    " L∆∞u √Ω: Vosk kh√¥ng h·ªó tr·ª£ t·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ. N·∫øu anh mu·ªën auto-detect ng√¥n ng·ªØ, anh c·∫ßn d√πng Whisper (c·ªßa OpenAI) thay v√¨ Vosk.\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53610e94-b22b-4bdd-9836-0f67888118de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytube\n",
    "#!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "#!pip install youtube-dlg\n",
    "#!pip install youtube-dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0e155-e866-4f4d-8f7c-cf17a77e5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "download_dir = './videoytb/'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# URL video YouTube\n",
    "video_url = \\\"https://www.youtube.com/watch?v=lqKapMX2GAI\\\"\n",
    "\n",
    "# C·∫•u h√¨nh t·∫£i\n",
    "ydl_opts = {\n",
    "    'format': 'bestvideo+bestaudio',                    # T·∫£i video v√† audio ri√™ng bi·ªát\n",
    "    'outtmpl': download_dir + '%(title)s.%(ext)s',      # L∆∞u v√†o th∆∞ m·ª•c ./videoytb/\n",
    "    'writesubtitles': True,                             # T·∫£i ph·ª• ƒë·ªÅ\n",
    "    'writeautomaticsub': True,                          # T·∫£i ph·ª• ƒë·ªÅ t·ª± ƒë·ªông n·∫øu kh√¥ng c√≥ ph·ª• ƒë·ªÅ g·ªëc\n",
    "    'subtitlesformat': 'srt',                           # ƒê·ªãnh d·∫°ng ph·ª• ƒë·ªÅ .srt\n",
    "    'subtitleslangs': ['en', 'vi'],                     # T·∫£i c·∫£ ph·ª• ƒë·ªÅ ti·∫øng Anh v√† ti·∫øng Vi·ªát\n",
    "#    'merge_output_format': 'mp4',                        # ƒê·∫£m b·∫£o video c√≥ h√¨nh v√† ti·∫øng\n",
    "    'postprocessors': [\n",
    "        {\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "            'nopostoverwrites': False\n",
    "        }\n",
    "    ],\n",
    "    'keepvideo': True                                   # Gi·ªØ file video ri√™ng bi·ªát, kh√¥ng merge\n",
    "}\n",
    "\n",
    "# T·∫£i video/audio/ph·ª• ƒë·ªÅ\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([video_url])\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdd694-2d09-4b6f-813b-e84065472786",
   "metadata": {},
   "source": [
    "# X·ª≠ l√Ω vƒÉn b·∫£n\n",
    "L∆∞u ph·ª• ƒë·ªÅ d∆∞·ªõi d·∫°ng script string ƒë·ªÉ s·ª≠ d·ª•ng cho AI Draw.io..\n",
    "\n",
    "# T·∫°o s∆° ƒë·ªì quy tr√¨nh\n",
    "D√πng AI Draw.io ƒë·ªÉ chuy·ªÉn n·ªôi dung th√†nh s∆° ƒë·ªì tr·ª±c quan.\n",
    "\n",
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "Tr∆∞·ªõc ti√™n, h√£y c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán h·ªó tr·ª£:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d395d0-20ec-455c-a191-597343bbffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube-transcript-api drawio pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ad021-9af0-4d66-9547-28c876876057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "\n",
    "# URL video YouTube\n",
    "video_url = \\\"https://www.youtube.com/watch?v=_KoifHHJhNY\\\"\n",
    "\n",
    "# L·∫•y ID video t·ª´ URL\n",
    "video_id = video_url.split(\\\"v=\\\")[-1].split(\\\"&\\\")[0]\n",
    "\n",
    "# L·∫•y ph·ª• ƒë·ªÅ (ti·∫øng Anh ho·∫∑c ti·∫øng Vi·ªát)\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en', 'vi'])\n",
    "\n",
    "# Chuy·ªÉn ph·ª• ƒë·ªÅ th√†nh script string\n",
    "script_text = \\\"\\\\n\\\".join([segment['text'] for segment in transcript])\n",
    "\n",
    "# L∆∞u v√†o file CSV\n",
    "df = pd.DataFrame(transcript)\n",
    "df.to_csv(r\\\"C:\\\\Python311\\\\ytb-api\\\\YOLO_Ultralytics.csv\\\", index=False)\n",
    "\n",
    "print(\\\"Ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c tr√≠ch xu·∫•t th√†nh c√¥ng!\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db62d9-520b-4528-9ab0-c6e857823de0",
   "metadata": {},
   "source": [
    "# Chuy·ªÉn vƒÉn b·∫£n th√†nh s∆° ƒë·ªì Draw.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b433b-ba70-495c-97fa-81b446969e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diagrams\n",
    "!python.exe -m pip install --upgrade pip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e1a5d-7123-42fe-9c8b-ab304bcd806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Diagram\n",
    "from diagrams.generic.blank import Blank\n",
    "\n",
    "with Diagram(\\\"Workflow Diagram\\\", show=False, filename=\\\"workflow\\\"):\n",
    "    Blank(\\\"Step 1\\\")\n",
    "    Blank(\\\"Step 2\\\")\n",
    "    Blank(\\\"Step 3\\\")\n",
    "\n",
    "# Load file vƒÉn b·∫£n ƒë√£ tr√≠ch xu·∫•t\n",
    "df = pd.read_csv(r\\\"C:\\\\Python311\\\\ytb-api\\\\youtube_subtitles.en.csv\\\")\n",
    "\n",
    "# Kh·ªüi t·∫°o s∆° ƒë·ªì\n",
    "diagram = DrawioDiagram(\\\"C:\\\\Python311\\\\ytb-api\\\\workflow.xml\\\")\n",
    "\n",
    "# Th√™m c√°c b∆∞·ªõc t·ª´ script\n",
    "for index, row in df.iterrows():\n",
    "    diagram.add_shape(row[\\\"Text\\\"], x=index*150, y=100)\n",
    "\n",
    "# L∆∞u s∆° ƒë·ªì d∆∞·ªõi d·∫°ng file Draw.io\n",
    "diagram.save()\n",
    "\n",
    "print(\\\"S∆° ƒë·ªì quy tr√¨nh ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ef79a-0843-4de3-be75-5baad8953b26",
   "metadata": {},
   "source": [
    "# Trong python 3.11 tr√™n windows 11 pro c√≥ open-webui v√† ollama 3.2:1b t√¥i c·∫ßn vi·∫øt code python sao cho c√≥ th·ªÉ load file mp4 video m√† c√≥ th·ªÉ chuy·ªÉn ƒëo·∫°n audio c√≥ ti·∫øng th√†nh file ph·ª• ƒë·ªÉ srt ki·ªÉu speech to text (kh√¥ng t√°ch file ti·∫øng audio)?\n",
    "\n",
    "M√£ Python ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ:\n",
    "\n",
    "- **X·ª≠ l√Ω tr·ª±c ti·∫øp file MP4** m√† kh√¥ng c·∫ßn t√°ch audio ri√™ng.\n",
    "- **Tr√≠ch xu·∫•t audio t·∫°m th·ªùi**, chuy·ªÉn th√†nh vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh **Whisper**.\n",
    "- **T·∫°o file ph·ª• ƒë·ªÅ `.srt`** v·ªõi th·ªùi gian hi·ªÉn th·ªã ch√≠nh x√°c.\n",
    "\n",
    "Tuy nhi√™n, h·ªá th·ªëng hi·ªán t·∫°i ch∆∞a c√†i s·∫µn th∆∞ vi·ªán `whisper`, n√™n kh√¥ng th·ªÉ ch·∫°y tr·ª±c ti·∫øp. Anh c√≥ th·ªÉ c√†i tr√™n m√°y Windows 11 Pro c·ªßa m√¨nh b·∫±ng l·ªánh:\n",
    "\n",
    "```bash\n",
    "pip install -U openai-whisper\n",
    "```\n",
    "\n",
    "### ‚úÖ G·ª£i √Ω c·∫•u h√¨nh m√¥i tr∆∞·ªùng:\n",
    "- Python 3.11\n",
    "- Windows 11 Pro\n",
    "- ƒê√£ c√†i `ffmpeg` (b·∫Øt bu·ªôc cho x·ª≠ l√Ω video/audio)\n",
    "- C√†i th√™m:\n",
    "  ```bash\n",
    "  pip install moviepy openai-whisper\n",
    "  ```\n",
    "\n",
    "### üìÑ File m√£ Python ho√†n ch·ªânh\n",
    "Anh c√≥ mu·ªën m√¨nh t·∫°o file `.py` ƒë·ªÉ anh t·∫£i v·ªÅ v√† ch·∫°y tr·ª±c ti·∫øp kh√¥ng?\n",
    "\n",
    "### T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ (n·∫øu d√πng Whisper)\n",
    "L∆∞u √Ω: Vosk kh√¥ng h·ªó tr·ª£ t·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ. N·∫øu anh mu·ªën auto-detect ng√¥n ng·ªØ, anh c·∫ßn d√πng Whisper (c·ªßa OpenAI) thay v√¨ Vosk.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3bf28-34ff-4fac-b3b1-b1e9591b6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy openai-whisper\n",
    "#!pip install -U openai-whisper\n",
    "\n",
    "!pip show moviepy\n",
    "!pip show openai-whisper\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44ff75-61f3-439d-b407-66b9695255bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "import whisper\n",
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n video\n",
    "video_path = r\\\"C:\\\\VideoData\\\\gnvh-the-che-chinh-sach-cho-bao-ton-phat-trien-di-san-van-hoa.mp4\\\"\n",
    "audio_path = r\\\"C:\\\\VideoData\\\\gnvh-the-che-chinh-sach-cho-bao-ton-phat-trien-di-san-van-hoa.wav\\\"\n",
    "srt_path = r\\\"C:\\\\VideoData\\\\gnvh-the-che-chinh-sach-cho-bao-ton-phat-trien-di-san-van-hoa.srt\\\"\n",
    "\n",
    "# T√°ch audio t·ª´ video\n",
    "video = VideoFileClip(video_path)\n",
    "video.audio.write_audiofile(audio_path, fps=16000, codec='pcm_s16le')\n",
    "\n",
    "# Load m√¥ h√¨nh Whisper\n",
    "model = whisper.load_model(\\\"base\\\")\n",
    "\n",
    "# Chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n\n",
    "result = model.transcribe(audio_path, language=\\\"vi\\\")\n",
    "\n",
    "# H√†m ƒë·ªãnh d·∫°ng th·ªùi gian ki·ªÉu SRT\n",
    "def format_timestamp(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\\\"{h:02}:{m:02}:{s:02},{ms:03}\\\"\n",
    "\n",
    "# Ghi file SRT\n",
    "with open(srt_path, \\\"w\\\", encoding=\\\"utf-8\\\") as srt_file:\n",
    "    for i, segment in enumerate(result[\\\"segments\\\"], start=1):\n",
    "        start = format_timestamp(segment[\\\"start\\\"])\n",
    "        end = format_timestamp(segment[\\\"end\\\"])\n",
    "        text = segment[\\\"text\\\"].strip()\n",
    "        srt_file.write(f\\\"{i}\\\\n{start} --> {end}\\\\n{text}\\\\n\\\\n\\\")\n",
    "        #srt_file.write(f\\\"{i}\\\\n{format_timestamp(start)} --> {format_timestamp(end)}\\\\n{text}\\\\n\\\\n\\\")\n",
    "\n",
    "# X√≥a file audio t·∫°m\n",
    "os.remove(audio_path)\n",
    "\n",
    "print(f\\\"‚úÖ Ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {srt_path}\\\")\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cd456-d801-44b0-926a-fbf13a3b5d8d",
   "metadata": {},
   "source": [
    "# Debug thay code \n",
    ">>> T√¥i ƒë√£ l√†m theo code python 3.11, file bat v√† khai b√°o bi·∫øn m√¥i tr∆∞·ªùng ƒë√∫ng nh∆∞ h∆∞·ªõng d·∫´n v√† v·∫´n b·ªã l·ªói tr√™n :\n",
    "ModuleNotFoundError Traceback (most recent call last) Cell In[1], line 1 ----> 1 from moviepy.editor import VideoFileClip 2 import whisper 3 import os ModuleNotFoundError: No module named 'moviepy.editor'\n",
    "theo b·∫°n c√≥ th·ªÉ n√™n thay th∆∞ vi·ªán v√† model trong python 3.11 v·ªõi m·ªôt thu·∫≠t to√°n ho·∫∑c th∆∞ vi·ªán ho·∫∑c model AI n√†o d·ªÖ d√πng v√† hi·ªáu qu·∫£ h∆°n ?\n",
    "---\n",
    "### T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ (n·∫øu d√πng Whisper)\n",
    "L∆∞u √Ω: Vosk kh√¥ng h·ªó tr·ª£ t·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ. N·∫øu anh mu·ªën auto-detect ng√¥n ng·ªØ, anh c·∫ßn d√πng Whisper (c·ªßa OpenAI) thay v√¨ Vosk.\n",
    "\n",
    "### ‚úÖ Gi·∫£i ph√°p thay th·∫ø: D√πng th∆∞ vi·ªán v√† m√¥ h√¨nh AI d·ªÖ tri·ªÉn khai h∆°n\n",
    "\n",
    "N·∫øu m·ª•c ti√™u l√† **chuy·ªÉn gi·ªçng n√≥i trong video th√†nh ph·ª• ƒë·ªÅ SRT**, th√¨ m√¨nh ƒë·ªÅ xu·∫•t c√°c l·ª±a ch·ªçn **d·ªÖ d√πng v√† hi·ªáu qu·∫£ h∆°n Whisper**:\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ **Thay th·∫ø Whisper b·∫±ng Vosk (Offline, nh·∫π, d·ªÖ d√πng)**\n",
    "\n",
    "- **∆Øu ƒëi·ªÉm**:\n",
    "  - Ch·∫°y ho√†n to√†n offline.\n",
    "  - Kh√¥ng c·∫ßn GPU.\n",
    "  - C√≥ m√¥ h√¨nh ti·∫øng Vi·ªát.\n",
    "  - D·ªÖ t√≠ch h·ª£p v·ªõi video/audio.\n",
    "\n",
    "- **C√†i ƒë·∫∑t**:\n",
    "  ```bash\n",
    "  pip install vosk moviepy\n",
    "  ```\n",
    "\n",
    "- **T·∫£i m√¥ h√¨nh ti·∫øng Vi·ªát**:  \n",
    "  https://alphacephei.com/vosk/models\n",
    "\n",
    "T·∫£i m√¥ h√¨nh ti·∫øng Vi·ªát\n",
    "Truy c·∫≠p: https://alphacephei.com/vosk/models\n",
    "T·∫£i: vosk-model-small-vn-0.4.zip  (https://alphacephei.com/vosk/models/vosk-model-small-vn-0.4.zip)\n",
    "Gi·∫£i n√©n v√†o th∆∞ m·ª•c: C:\\\\vosk\\\\vosk-model-small-vn-0.4\n",
    "---\n",
    "\n",
    "### üì¶ G·ª£i √Ω th∆∞ vi·ªán thay th·∫ø:\n",
    "\n",
    "| M·ª•c ti√™u | Th∆∞ vi·ªán | M√¥ h√¨nh | Ghi ch√∫ |\n",
    "|---------|----------|---------|--------|\n",
    "| T√°ch audio t·ª´ video | `moviepy` ho·∫∑c `ffmpeg-python` | ‚Äî | D·ªÖ d√πng |\n",
    "| Nh·∫≠n d·∫°ng gi·ªçng n√≥i | `vosk` | m√¥ h√¨nh `.zip` ti·∫øng Vi·ªát | Nh·∫π, offline |\n",
    "| T·∫°o ph·ª• ƒë·ªÅ SRT | T·ª± vi·∫øt ho·∫∑c d√πng `autosrt` | ‚Äî | T·ª± ƒë·ªông h√≥a |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† N·∫øu mu·ªën d√πng m√¥ h√¨nh AI n√¢ng cao nh∆∞ Ollama 3.2:1b\n",
    "\n",
    "Hi·ªán t·∫°i Ollama ch·ªß y·∫øu h·ªó tr·ª£ **x·ª≠ l√Ω vƒÉn b·∫£n**, ch∆∞a c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω **audio tr·ª±c ti·∫øp** nh∆∞ Whisper hay Vosk. N·∫øu anh mu·ªën t√≠ch h·ª£p Ollama ƒë·ªÉ **d·ªãch ho·∫∑c t√≥m t·∫Øt n·ªôi dung ph·ª• ƒë·ªÅ**, th√¨ c√≥ th·ªÉ d√πng sau b∆∞·ªõc nh·∫≠n d·∫°ng gi·ªçng n√≥i.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Anh c√≥ mu·ªën m√¨nh t·∫°o l·∫°i m√£ Python d√πng `vosk` ƒë·ªÉ:\n",
    "\n",
    "- Load video MP4\n",
    "- T√°ch audio t·∫°m th·ªùi\n",
    "- Nh·∫≠n d·∫°ng gi·ªçng n√≥i b·∫±ng m√¥ h√¨nh ti·∫øng Vi·ªát\n",
    "- T·∫°o file `.srt` ph·ª• ƒë·ªÅ\n",
    "\n",
    "try:\n",
    "```\n",
    "from moviepy import VideoFileClip\n",
    "```\n",
    "instead of:\n",
    "```\n",
    "from moviepy.editor import VideoFileClip\n",
    "```\n",
    "It works.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc160e-5f3c-4c7e-847e-798780378261",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vosk moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513d7b9-b128-4f70-bbfc-3605b92f9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from moviepy import VideoFileClip\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi video MP4\n",
    "video_path = r\\\"C:\\\\VideoData\\\\vCenterHA8x_Demo.mp4\\\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·∫°m ƒë·ªÉ l∆∞u audio WAV\n",
    "audio_path = r\\\"C:\\\\VideoData\\\\vCenterHA8x_Demo.wav\\\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh Vosk ti·∫øng Vi·ªát ƒë√£ gi·∫£i n√©n\n",
    "vosk_model_path = r\\\"c:\\\\vosk\\\\vosk-model-small-vn-0.4\\\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file ph·ª• ƒë·ªÅ SRT\n",
    "srt_output_path = r\\\"C:\\\\VideoData\\\\vCenterHA8x_Demo.srt\\\"\n",
    "\n",
    "# B∆∞·ªõc 1: T√°ch audio t·ª´ video v√† l∆∞u th√†nh WAV mono 16kHz\n",
    "video = VideoFileClip(video_path)\n",
    "video.audio.write_audiofile(audio_path, fps=16000, codec='pcm_s16le')\n",
    "\n",
    "# B∆∞·ªõc 2: Load m√¥ h√¨nh Vosk\n",
    "model = Model(vosk_model_path)\n",
    "\n",
    "# B∆∞·ªõc 3: M·ªü file audio WAV\n",
    "wf = wave.open(audio_path, \\\"rb\\\")\n",
    "recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "recognizer.SetWords(True)\n",
    "\n",
    "# B∆∞·ªõc 4: Nh·∫≠n d·∫°ng gi·ªçng n√≥i v√† l∆∞u c√°c ƒëo·∫°n c√≥ th·ªùi gian\n",
    "results = []\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = json.loads(recognizer.Result())\n",
    "        results.append(result)\n",
    "# L·∫•y k·∫øt qu·∫£ cu·ªëi c√πng\n",
    "final_result = json.loads(recognizer.FinalResult())\n",
    "results.append(final_result)\n",
    "\n",
    "# B∆∞·ªõc 5: Chuy·ªÉn k·∫øt qu·∫£ th√†nh ƒë·ªãnh d·∫°ng SRT\n",
    "def format_timestamp(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\\\"{h:02}:{m:02}:{s:02},{ms:03}\\\"\n",
    "\n",
    "segments = []\n",
    "index = 1\n",
    "for res in results:\n",
    "    if \\\"result\\\" in res:\n",
    "        words = res[\\\"result\\\"]\n",
    "        if words:\n",
    "            start = words[0][\\\"start\\\"]\n",
    "            end = words[-1][\\\"end\\\"]\n",
    "            text = \\\" \\\".join([w[\\\"word\\\"] for w in words])\n",
    "            segments.append((index, start, end, text))\n",
    "            index += 1\n",
    "\n",
    "# B∆∞·ªõc 6: Ghi file SRT\n",
    "with open(srt_output_path, \\\"w\\\", encoding=\\\"utf-8\\\") as srt_file:\n",
    "    for seg in segments:\n",
    "        i, start, end, text = seg\n",
    "        srt_file.write(f\\\"{i}\\\\n{format_timestamp(start)} --> {format_timestamp(end)}\\\\n{text}\\\\n\\\\n\\\")\n",
    "\n",
    "# B∆∞·ªõc 7: X√≥a file audio t·∫°m\n",
    "wf.close()\n",
    "os.remove(audio_path)\n",
    "\n",
    "print(f\\\"‚úÖ Ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {srt_output_path}\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261892fc-2a17-4e9e-ad0b-d666243dadeb",
   "metadata": {},
   "source": [
    "# Download YTB File MP4, Audio MP3, Ph·ª• ƒë·ªÅ srt t·ªõi C:\\\\VideoData \n",
    "Th√°nh ƒê·ª©c Dalai Lama ti·∫øt l·ªô s·ª± th·∫≠t v·ªÅ k√Ω ·ª©c ti·ªÅn ki·∫øp khi·∫øn c√°c nh√† khoa h·ªçc l·∫∑ng ng∆∞·ªùi: \n",
    "https://www.youtube.com/watch?v=89Q_B7zdgNc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303fe09-addb-4442-be4f-ca165966561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytube\n",
    "#!pip install --upgrade pytube\n",
    "!pip install yt-dlp\n",
    "#!pip install youtube-dlg\n",
    "#!pip install youtube-dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0815a-8696-4989-9e66-0fc0b89959d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "download_dir = 'C:\\\\\\\\VideoData\\\\\\\\'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# URL video YouTube\n",
    "video_url = \\\"https://www.youtube.com/watch?v=89Q_B7zdgNc\\\"\n",
    "\n",
    "# C·∫•u h√¨nh t·∫£i\n",
    "ydl_opts = {\n",
    "    'format': 'bestvideo+bestaudio',                    # T·∫£i video v√† audio ri√™ng bi·ªát\n",
    "    'outtmpl': download_dir + '%(title)s.%(ext)s',      # L∆∞u v√†o th∆∞ m·ª•c ./videoytb/\n",
    "    'writesubtitles': True,                             # T·∫£i ph·ª• ƒë·ªÅ\n",
    "    'writeautomaticsub': True,                          # T·∫£i ph·ª• ƒë·ªÅ t·ª± ƒë·ªông n·∫øu kh√¥ng c√≥ ph·ª• ƒë·ªÅ g·ªëc\n",
    "    'subtitlesformat': 'srt',                           # ƒê·ªãnh d·∫°ng ph·ª• ƒë·ªÅ .srt\n",
    "    'subtitleslangs': ['en', 'vi'],                     # T·∫£i c·∫£ ph·ª• ƒë·ªÅ ti·∫øng Anh v√† ti·∫øng Vi·ªát\n",
    "#    'merge_output_format': 'mp4',                        # ƒê·∫£m b·∫£o video c√≥ h√¨nh v√† ti·∫øng\n",
    "    'postprocessors': [\n",
    "        {\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "            'nopostoverwrites': False\n",
    "        }\n",
    "    ],\n",
    "    'keepvideo': True                                   # Gi·ªØ file video ri√™ng bi·ªát, kh√¥ng merge\n",
    "}\n",
    "\n",
    "# T·∫£i video/audio/ph·ª• ƒë·ªÅ\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([video_url])\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df812a9-962e-49c4-b566-60aecca1e3ac",
   "metadata": {},
   "source": [
    "# Ph√¢n t√≠ch, t√≥m t·∫Øt, tr√≠ch xu·∫•t, l·∫•y highlight l√†m s∆° ƒë·ªì h√≥a n·ªôi dung ph·ª• ƒë·ªÅ \n",
    "video subtitles to: C:\\\\VideoData\\\\Th√°nh ƒê·ª©c Dalai Lama ti·∫øt l·ªô s·ª± th·∫≠t v·ªÅ k√Ω ·ª©c ti·ªÅn ki·∫øp khi·∫øn c√°c nh√† khoa h·ªçc l·∫∑ng ng∆∞·ªùi.vi.srt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac7002-931f-47c7-a627-50f203277a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env\n",
    "load_dotenv()\n",
    "\n",
    "# L·∫•y gi√° tr·ªã c·ªßa bi·∫øn m√¥i tr∆∞·ªùng GOOGLE_API_KEY\n",
    "google_api_key = os.getenv(\\\"GOOGLE_API_KEY\\\")\n",
    "\n",
    "# Ki·ªÉm tra xem bi·∫øn m√¥i tr∆∞·ªùng c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "if google_api_key is None:\n",
    "    raise ValueError(\\\"GOOGLE_API_KEY not found in environment variables or .env file.\\\")\n",
    "\n",
    "# S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ kh·ªüi t·∫°o client\n",
    "client = genai.Client(api_key=google_api_key)\n",
    "response = client.models.generate_content(\n",
    "    model=\\\"gemini-2.5-flash\\\", contents=\\\"\\\"\\\"\n",
    "T√¥i ƒë√£ ph·ª• ƒë·ªÅ ti·∫øng Vi·ªát: r'C:\\\\\\\\VideoData\\\\\\\\Th√°nh ƒê·ª©c Dalai Lama ti·∫øt l·ªô s·ª± th·∫≠t v·ªÅ k√Ω ·ª©c ti·ªÅn ki·∫øp khi·∫øn c√°c nh√† khoa h·ªçc l·∫∑ng ng∆∞·ªùi.vi.srt'.\n",
    "H√£y vi·∫øt cho t√¥i h√†m python 3.11 Jupyter Notebook v·ªõi model AI Gemeni-2.5-flash cho long context y√™u c·∫ßu nh·∫≠p API_key, sao cho c√≥ th·ªÉ ƒë·ªçc n·ªôi dung file srt n√™u tr√™n sau ƒë√≥\n",
    "th·ª±c hi·ªán 3 y√™u c·∫ßu sau:\n",
    "1. H√£y vi·∫øt ph√¢n t√≠ch tr√≠ch xu·∫•t, t√≥m t·∫Øt, l·∫•y c√°c highlight c√°c keywords.\n",
    "2. V·∫Ω ra s∆° ƒë·ªì drawio theo format mermaid graph TD.\n",
    "3. H√£y L·∫≠p ra b·∫£ng Dashboard insight: Danh s√°ch c√°ch kh√°i ni·ªám, keywords, th√™m ch√∫ th√≠ch/ gi·∫£i th√≠ch/ghi ch√∫. \n",
    "    \\\"\\\"\\\"\n",
    ")\n",
    "print(response.text)\n",
    "# N·∫øu b·∫°n vi·∫øt r·∫±ng \\\"Xin l∆∞u √Ω r·∫±ng v√¨ t√¥i kh√¥ng c√≥ n·ªôi dung file SRT th·ª±c t·∫ø, c√°c ph√¢n t√≠ch d∆∞·ªõi ƒë√¢y \n",
    "# s·∫Ω d·ª±a tr√™n th√¥ng tin t·ª´ ti√™u ƒë·ªÅ, \n",
    "# ki·∫øn th·ª©c chung v·ªÅ ch·ªß ƒë·ªÅ n√†y v√† nh·ªØng n·ªôi dung th∆∞·ªùng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong c√°c video t∆∞∆°ng t·ª±.\\\"\n",
    "# th√¨ c√≥ c√°ch n√†o b·∫°n h√£y ch·ªâ cho t√¥i c·ª• th·ªÉ ƒë·ªÅ  b·∫°n c√≥ th·ªÉ ti·∫øp c·∫≠n n·ªôi dung file srt n√†y ? \n",
    "# v√≠ d·ª• vi·∫øt code python ? upload file ??\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe7164-0f20-4091-bbb2-dc525d78b5c5",
   "metadata": {},
   "source": [
    "# M√£ ƒë∆∞·ª£c copy /paste\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75634b7-ae62-43e0-a105-fc8e3bf14360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from IPython.display import display, Markdown # ƒê·ªÉ hi·ªÉn th·ªã n·ªôi dung Markdown v√† Mermaid trong Jupyter\n",
    "import pandas as pd\n",
    "import re # ƒê·ªÉ tr√≠ch xu·∫•t m√£ Mermaid\n",
    "\n",
    "# --- H√†m h·ªó tr·ª£ ƒë·ªçc file SRT ---\n",
    "def read_srt_content(file_path):\n",
    "    \\\"\\\"\\\"\n",
    "    ƒê·ªçc n·ªôi dung vƒÉn b·∫£n t·ª´ file SRT, b·ªè qua c√°c d√≤ng s·ªë th·ª© t·ª± v√† m·ªëc th·ªùi gian.\n",
    "    \\\"\\\"\\\"\n",
    "    text_content = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:  # B·ªè qua d√≤ng tr·ªëng\n",
    "                    continue\n",
    "                if line.isdigit() and len(line) < 5:  # B·ªè qua s·ªë th·ª© t·ª± (∆∞·ªõc l∆∞·ª£ng ƒë∆°n gi·∫£n)\n",
    "                    continue\n",
    "                if '-->' in line:  # B·ªè qua m·ªëc th·ªùi gian\n",
    "                    continue\n",
    "                text_content.append(line)\n",
    "    except FileNotFoundError:\n",
    "        return None, \\\"L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i ƒë∆∞·ªùng d·∫´n ƒë√£ cho.\\\"\n",
    "    except Exception as e:\n",
    "        return None, f\\\"L·ªói khi ƒë·ªçc file: {e}\\\"\n",
    "    return \\\"\\\\n\\\".join(text_content), None\n",
    "\n",
    "# --- H√†m h·ªó tr·ª£ tr√≠ch xu·∫•t m√£ Mermaid ---\n",
    "def extract_mermaid_code(text):\n",
    "    \\\"\\\"\\\"\n",
    "    Tr√≠ch xu·∫•t block m√£ Mermaid t·ª´ ph·∫£n h·ªìi c·ªßa model.\n",
    "    \\\"\\\"\\\"\n",
    "    match = re.search(r\\\"```mermaid\\\\n(.*?)\\\\n```\\\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# --- H√†m ch√≠nh ph√¢n t√≠ch SRT b·∫±ng Gemini ---\n",
    "def analyze_srt_with_gemini(srt_file_path):\n",
    "    \\\"\\\"\\\"\n",
    "    Ph√¢n t√≠ch n·ªôi dung file SRT s·ª≠ d·ª•ng Gemini 1.5 Flash v√† hi·ªÉn th·ªã k·∫øt qu·∫£.\n",
    "\n",
    "    Args:\n",
    "        srt_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file SRT c·∫ßn ph√¢n t√≠ch.\n",
    "    \\\"\\\"\\\"\n",
    "\n",
    "    # 0. Y√™u c·∫ßu nh·∫≠p API Key\n",
    "    # ∆Øu ti√™n l·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng, n·∫øu kh√¥ng c√≥ th√¨ y√™u c·∫ßu nh·∫≠p\n",
    "    api_key = os.getenv(\\\"GOOGLE_API_KEY\\\")\n",
    "    if not api_key:\n",
    "        api_key = input(\\\"Vui l√≤ng nh·∫≠p GOOGLE_API_KEY c·ªßa b·∫°n: \\\")\n",
    "        os.environ[\\\"GOOGLE_API_KEY\\\"] = api_key # ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng cho phi√™n hi·ªán t·∫°i\n",
    "\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "    except Exception as e:\n",
    "        print(f\\\"L·ªói c·∫•u h√¨nh Gemini API: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i GOOGLE_API_KEY c·ªßa b·∫°n.\\\")\n",
    "        return\n",
    "\n",
    "    # 1. ƒê·ªçc n·ªôi dung file SRT\n",
    "    srt_text, error = read_srt_content(srt_file_path)\n",
    "    if error:\n",
    "        print(error)\n",
    "        return\n",
    "\n",
    "    print(f\\\"ƒê√£ ƒë·ªçc th√†nh c√¥ng n·ªôi dung SRT t·ª´ '{srt_file_path}'. T·ªïng c·ªông {len(srt_text.splitlines())} d√≤ng.\\\")\n",
    "\n",
    "    # Kh·ªüi t·∫°o model Gemini 1.5 Flash (long context)\n",
    "    # L∆∞u √Ω: Model c√¥ng khai hi·ªán t·∫°i l√† 'gemini-1.5-flash-latest', kh√¥ng ph·∫£i 'gemini-2.5-flash'\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "    generation_config = {\n",
    "        \\\"temperature\\\": 0.7,      # ƒêi·ªÅu ch·ªânh s·ª± s√°ng t·∫°o c·ªßa model\n",
    "        \\\"top_p\\\": 1,\n",
    "        \\\"top_k\\\": 1,\n",
    "        \\\"max_output_tokens\\\": 8192 # TƒÉng gi·ªõi h·∫°n output ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªß n·ªôi dung\n",
    "    }\n",
    "\n",
    "    print(\\\"\\\\n--- B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH V·ªöI GEMINI ---\\\\n\\\")\n",
    "\n",
    "    # --- Y√™u c·∫ßu 1: Ph√¢n t√≠ch tr√≠ch xu·∫•t, t√≥m t·∫Øt, highlight, keywords ---\n",
    "    print(\\\"### 1. Ph√¢n t√≠ch, T√≥m t·∫Øt, Highlight & Keywords\\\")\n",
    "    prompt_analysis = f\\\"\\\"\\\"\n",
    "    B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch vƒÉn b·∫£n. H√£y ph√¢n t√≠ch n·ªôi dung sau ƒë√¢y t·ª´ m·ªôt file ph·ª• ƒë·ªÅ ti·∫øng Vi·ªát v·ªÅ ch·ªß ƒë·ªÅ 'Th√°nh ƒê·ª©c Dalai Lama ti·∫øt l·ªô s·ª± th·∫≠t v·ªÅ k√Ω ·ª©c ti·ªÅn ki·∫øp khi·∫øn c√°c nh√† khoa h·ªçc l·∫∑ng ng∆∞·ªùi'.\n",
    "\n",
    "    N·ªôi dung ƒë·∫ßy ƒë·ªß:\n",
    "    ```text\n",
    "    {srt_text}\n",
    "    ```\n",
    "\n",
    "    Vui l√≤ng th·ª±c hi·ªán c√°c y√™u c·∫ßu sau:\n",
    "    1.  **Ph√¢n t√≠ch & T√≥m t·∫Øt**: T√≥m t·∫Øt n·ªôi dung ch√≠nh m·ªôt c√°ch ng·∫Øn g·ªçn, s√∫c t√≠ch, bao qu√°t to√†n b·ªô b√†i n√≥i.\n",
    "    2.  **Highlight**: N√™u b·∫≠t c√°c ƒëi·ªÉm ch√≠nh, s·ª± ki·ªán ho·∫∑c lu·∫≠n ƒëi·ªÉm quan tr·ªçng nh·∫•t ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p (v√≠ d·ª•: c√°c th√≠ nghi·ªám, c√°c tr∆∞·ªùng h·ª£p c·ª• th·ªÉ, k·∫øt lu·∫≠n c·ªßa Dalai Lama).\n",
    "    3.  **Keywords**: Li·ªát k√™ c√°c t·ª´ kh√≥a quan tr·ªçng v√† n·ªïi b·∫≠t, t√°ch bi·ªát b·∫±ng d·∫•u ph·∫©y.\n",
    "\n",
    "    ƒê·ªãnh d·∫°ng tr·∫£ l·ªùi b·∫±ng Markdown.\n",
    "    \\\"\\\"\\\"\n",
    "    try:\n",
    "        response_analysis = model.generate_content(prompt_analysis, generation_config=generation_config)\n",
    "        display(Markdown(response_analysis.text))\n",
    "    except Exception as e:\n",
    "        print(f\\\"L·ªói khi th·ª±c hi·ªán ph√¢n t√≠ch/t√≥m t·∫Øt: {e}\\\")\n",
    "\n",
    "    # --- Y√™u c·∫ßu 2: V·∫Ω s∆° ƒë·ªì Draw.io theo format Mermaid graph TD ---\n",
    "    print(\\\"\\\\n### 2. S∆° ƒë·ªì Draw.io (Mermaid Graph TD)\\\")\n",
    "    prompt_mermaid = f\\\"\\\"\\\"\n",
    "    D·ª±a tr√™n n·ªôi dung ch√≠nh c·ªßa vƒÉn b·∫£n ph·ª• ƒë·ªÅ sau ƒë√¢y v·ªÅ Th√°nh ƒê·ª©c Dalai Lama v√† k√Ω ·ª©c ti·ªÅn ki·∫øp:\n",
    "\n",
    "    N·ªôi dung:\n",
    "    ```text\n",
    "    {srt_text}\n",
    "    ```\n",
    "\n",
    "    H√£y t·∫°o m·ªôt bi·ªÉu ƒë·ªì Mermaid (format `graph TD`) ƒë·ªÉ minh h·ªça c√°c kh√°i ni·ªám, th·ª±c th·ªÉ v√† m·ªëi quan h·ªá ch√≠nh. T·∫≠p trung v√†o:\n",
    "    -   Dalai Lama\n",
    "    -   K√Ω ·ª©c ti·ªÅn ki·∫øp\n",
    "    -   Khoa h·ªçc (C√°c nh√† khoa h·ªçc)\n",
    "    -   B·∫±ng ch·ª©ng / Nghi√™n c·ª©u (nh∆∞ c·ªßa TS. Ian Stevenson)\n",
    "    -   Ph·∫≠t gi√°o / T√°i sinh / Lu√¢n h·ªìi\n",
    "    -   √ù th·ª©c / T√¢m th·ª©c\n",
    "    -   Tr·∫ª em c√≥ k√Ω ·ª©c ti·ªÅn ki·∫øp\n",
    "    -   Nghi√™n c·ª©u khoa h·ªçc vs. quan ƒëi·ªÉm Ph·∫≠t gi√°o\n",
    "\n",
    "    Ch·ªâ tr·∫£ v·ªÅ block m√£ Mermaid, kh√¥ng c√≥ b·∫•t k·ª≥ vƒÉn b·∫£n gi·∫£i th√≠ch n√†o kh√°c. M√£ ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng ````mermaid` v√† k·∫øt th√∫c b·∫±ng ````. ƒê·∫£m b·∫£o c·∫•u tr√∫c r√µ r√†ng v√† d·ªÖ hi·ªÉu.\n",
    "    \\\"\\\"\\\"\n",
    "    try:\n",
    "        response_mermaid = model.generate_content(prompt_mermaid, generation_config=generation_config)\n",
    "        mermaid_code = extract_mermaid_code(response_mermaid.text)\n",
    "        if mermaid_code:\n",
    "            print(\\\"ƒê·ªÉ xem s∆° ƒë·ªì, b·∫°n c√≥ th·ªÉ copy m√£ d∆∞·ªõi ƒë√¢y v√†o m·ªôt c√¥ng c·ª• h·ªó tr·ª£ Mermaid (nh∆∞ Draw.io ho·∫∑c VS Code v·ªõi extension Mermaid Preview), ho·∫∑c Jupyter Notebook c√≥ th·ªÉ t·ª± render n·∫øu c√≥ g√≥i hi·ªÉn th·ªã Mermaid.\\\")\n",
    "            display(Markdown(f\\\"```mermaid\\\\n{mermaid_code}\\\\n```\\\"))\n",
    "        else:\n",
    "            print(\\\"Kh√¥ng t√¨m th·∫•y m√£ Mermaid h·ª£p l·ªá trong ph·∫£n h·ªìi c·ªßa model.\\\")\n",
    "            print(\\\"Ph·∫£n h·ªìi g·ªëc:\\\\n\\\", response_mermaid.text) # Hi·ªÉn th·ªã ph·∫£n h·ªìi g·ªëc ƒë·ªÉ debug\n",
    "    except Exception as e:\n",
    "        print(f\\\"L·ªói khi t·∫°o s∆° ƒë·ªì Mermaid: {e}\\\")\n",
    "\n",
    "    # --- Y√™u c·∫ßu 3: L·∫≠p b·∫£ng Dashboard insight ---\n",
    "    print(\\\"\\\\n### 3. B·∫£ng Dashboard Insight\\\")\n",
    "    prompt_dashboard = f\\\"\\\"\\\"\n",
    "    D·ª±a tr√™n n·ªôi dung ch√≠nh c·ªßa vƒÉn b·∫£n ph·ª• ƒë·ªÅ sau ƒë√¢y v·ªÅ Th√°nh ƒê·ª©c Dalai Lama v√† k√Ω ·ª©c ti·ªÅn ki·∫øp:\n",
    "\n",
    "    N·ªôi dung:\n",
    "    ```text\n",
    "    {srt_text}\n",
    "    ```\n",
    "\n",
    "    H√£y t·∫°o m·ªôt b·∫£ng Dashboard Insight v·ªõi 3 c·ªôt: 'Kh√°i ni·ªám/Keywords', 'Ch√∫ th√≠ch/Gi·∫£i th√≠ch', v√† 'Ghi ch√∫/Insights'.\n",
    "    ƒêi·ªÅn v√†o b·∫£ng n√†y √≠t nh·∫•t 7-10 kh√°i ni·ªám v√† t·ª´ kh√≥a quan tr·ªçng ƒë√£ x√°c ƒë·ªãnh, cung c·∫•p gi·∫£i th√≠ch ng·∫Øn g·ªçn cho t·ª´ng m·ª•c v√† b·∫•t k·ª≥ th√¥ng tin chi ti·∫øt ho·∫∑c k·∫øt n·ªëi li√™n quan n√†o.\n",
    "    ƒê·ªãnh d·∫°ng b·∫£ng b·∫±ng Markdown, s·ª≠ d·ª•ng d·∫•u `|` ƒë·ªÉ ph√¢n t√°ch c·ªôt v√† `--` cho d√≤ng ti√™u ƒë·ªÅ.\n",
    "    \\\"\\\"\\\"\n",
    "    try:\n",
    "        response_dashboard = model.generate_content(prompt_dashboard, generation_config=generation_config)\n",
    "        dashboard_md_table = response_dashboard.text\n",
    "        # Th·ª≠ chuy·ªÉn ƒë·ªïi Markdown table sang Pandas DataFrame ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n\n",
    "        try:\n",
    "            from io import StringIO\n",
    "            df = pd.read_csv(StringIO(dashboard_md_table), sep='|', engine='python', skipinitialspace=True)\n",
    "            # Cleanup dataframe (remove leading/trailing pipes, strip spaces, remove empty rows)\n",
    "            df = df.iloc[1:].apply(lambda x: x.str.strip(), axis=1) # Strip spaces and remove header separator line\n",
    "            df.columns = [col.strip() for col in df.columns] # Clean column names\n",
    "            df = df.dropna(axis=1, how='all') # Drop fully empty columns (e.g., first/last '|' in markdown)\n",
    "            df = df.loc[:, df.columns.isin(['Kh√°i ni·ªám/Keywords', 'Ch√∫ th√≠ch/Gi·∫£i th√≠ch', 'Ghi ch√∫/Insights'])] # Keep only relevant columns\n",
    "            display(df)\n",
    "        except Exception as e:\n",
    "            print(f\\\"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi b·∫£ng Markdown sang Pandas DataFrame. Hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng Markdown th√¥. L·ªói: {e}\\\")\n",
    "            display(Markdown(dashboard_md_table))\n",
    "    except Exception as e:\n",
    "        print(f\\\"L·ªói khi t·∫°o b·∫£ng Dashboard Insight: {e}\\\")\n",
    "\n",
    "    print(\\\"\\\\n--- HO√ÄN TH√ÄNH PH√ÇN T√çCH ---\\\")\n",
    "\n",
    "# --- C√°ch s·ª≠ d·ª•ng trong Jupyter Notebook ---\n",
    "if __name__ == '__main__':\n",
    "    # ƒê·∫∑t ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c ƒë·∫øn file SRT c·ªßa b·∫°n\n",
    "    # V√≠ d·ª•: n·∫øu file n·∫±m trong c√πng th∆∞ m·ª•c v·ªõi notebook, ch·ªâ c·∫ßn t√™n file\n",
    "    # srt_file_path = \\\"Th√°nh ƒê·ª©c Dalai Lama ti·∫øt l·ªô s·ª± th·∫≠t v·ªÅ k√Ω ·ª©c ti·ªÅn ki·∫øp khi·∫øn c√°c nh√† khoa h·ªçc l·∫∑ng ng∆∞·ªùi.vi.srt\\\"\n",
    "    # Ho·∫∑c ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi nh∆∞ b·∫°n ƒë√£ cung c·∫•p:\n",
    "    srt_file_path = r'C:\\\\\\\\VideoData\\\\\\\\Th√°nh ƒê·ª©c Dalai Lama ti·∫øt l·ªô s·ª± th·∫≠t v·ªÅ k√Ω ·ª©c ti·ªÅn ki·∫øp khi·∫øn c√°c nh√† khoa h·ªçc l·∫∑ng ng∆∞·ªùi.vi.srt'\n",
    "\n",
    "    analyze_srt_with_gemini(srt_file_path)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a538142-c3cf-4d6b-8259-9734598bacb5",
   "metadata": {},
   "source": [
    "# Veo 3 c·ªßa Gemini google\n",
    "_https://ai.google.dev/gemini-api/docs/video?example=dialogue_\n",
    "\n",
    "## Generating videos from images\n",
    "_The following code demonstrates generating an image using Imagen, then using that image as the starting frame for generating video with Veo 3_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9775285-7fd8-44d4-baf6-198c2046e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = \\\"\\\"\\\"A close up of two people staring at a cryptic drawing on a wall, torchlight flickering.\n",
    "A man murmurs, 'This must be it. That's the secret code.' The woman looks at him and whispering excitedly, 'What did you find?'\\\"\\\"\\\"\n",
    "\n",
    "operation = client.models.generate_videos(\n",
    "    model=\\\"veo-3.0-generate-preview\\\",\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "# Poll the operation status until the video is ready.\n",
    "while not operation.done:\n",
    "    print(\\\"Waiting for video generation to complete...\\\")\n",
    "    time.sleep(10)\n",
    "    operation = client.operations.get(operation)\n",
    "\n",
    "# Download the generated video.\n",
    "generated_video = operation.response.generated_videos[0]\n",
    "client.files.download(file=generated_video.video)\n",
    "generated_video.video.save(\\\"dialogue_example.mp4\\\")\n",
    "print(\\\"Generated video saved to dialogue_example.mp4\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15101ff6-9b50-4464-a8b6-5f22f606d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = \\\"Panning wide shot of a calico kitten sleeping in the sunshine\\\"\n",
    "\n",
    "# Step 1: Generate an image with Imagen.\n",
    "imagen = client.models.generate_images(\n",
    "    model=\\\"imagen-3.0-generate-002\\\",\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "# Step 2: Generate video with Veo 3 using the image.\n",
    "operation = client.models.generate_videos(\n",
    "    model=\\\"veo-3.0-generate-preview\\\",\n",
    "    prompt=prompt,\n",
    "    image=imagen.generated_images[0].image,\n",
    ")\n",
    "\n",
    "# Poll the operation status until the video is ready.\n",
    "while not operation.done:\n",
    "    print(\\\"Waiting for video generation to complete...\\\")\n",
    "    time.sleep(10)\n",
    "    operation = client.operations.get(operation)\n",
    "\n",
    "# Download the video.\n",
    "video = operation.response.generated_videos[0]\n",
    "client.files.download(file=video.video)\n",
    "video.video.save(\\\"veo3_with_image_input.mp4\\\")\n",
    "print(\\\"Generated video saved to veo3_with_image_input.mp4\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ab775-9939-4b79-bf20-3dcaf1080f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = \\\"\\\"\\\"A close up of two people staring at a cryptic drawing on a wall, torchlight flickering.\n",
    "A man murmurs, 'This must be it. That's the secret code.' The woman looks at him and whispering excitedly, 'What did you find?'\\\"\\\"\\\"\n",
    "\n",
    "operation = client.models.generate_videos(\n",
    "    model=\\\"veo-3.0-generate-preview\\\",\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "# Poll the operation status until the video is ready.\n",
    "while not operation.done:\n",
    "    print(\\\"Waiting for video generation to complete...\\\")\n",
    "    time.sleep(10)\n",
    "    operation = client.operations.get(operation)\n",
    "\n",
    "# Download the generated video.\n",
    "generated_video = operation.response.generated_videos[0]\n",
    "client.files.download(file=generated_video.video)\n",
    "generated_video.video.save(\\\"dialogue_example.mp4\\\")\n",
    "print(\\\"Generated video saved to dialogue_example.mp4\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9400c-ce7c-44c9-8b48-35b09dbfc402",
   "metadata": {},
   "source": [
    "# Download video, transcription from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe902208-c43c-4fc5-b7ac-bfee853b3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f55be-5ff8-4dd7-9832-8e85fdee3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "def download_from_gdrive(url, output_path):\n",
    "    \\\"\\\"\\\"\n",
    "    T·∫£i m·ªôt file t·ª´ Google Drive URL v·ªÅ ƒë∆∞·ªùng d·∫´n c·ª•c b·ªô ƒë√£ ch·ªâ ƒë·ªãnh.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL c·ªßa file tr√™n Google Drive (c·∫£ d·∫°ng view v√† share).\n",
    "        output_path (str): ƒê∆∞·ªùng d·∫´n v√† t√™n file ƒë·ªÉ l∆∞u v·ªÅ m√°y.\n",
    "    \\\"\\\"\\\"\n",
    "    try:\n",
    "        print(f\\\"ƒêang b·∫Øt ƒë·∫ßu t·∫£i t·ª´: {url}\\\")\n",
    "        print(f\\\"L∆∞u file t·∫°i: {output_path}\\\")\n",
    "        \n",
    "        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # D√πng gdown ƒë·ªÉ t·∫£i file\n",
    "        # quiet=False ƒë·ªÉ hi·ªÉn th·ªã ti·∫øn tr√¨nh t·∫£i\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "        \n",
    "        print(\\\"\\\\nT·∫£i file th√†nh c√¥ng!\\\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\\\"\\\\nƒê√£ x·∫£y ra l·ªói: {e}\\\")\n",
    "        return False\n",
    "\n",
    "# --- PH·∫¶N CH√çNH ƒê·ªÇ B·∫†N CH·∫†Y ---\n",
    "if __name__ == \\\"__main__\\\":\n",
    "    # URL c·ªßa video MP4 c·ªßa b·∫°n\n",
    "    video_url = \\\"https://drive.google.com/file/d/17eLum7L4nd6aU4WIRAKssexcBwTzb1_x/view\\\"\n",
    "    video_output = \\\"downloads/my_video.mp4\\\"\n",
    "    \n",
    "    # G·ªçi h√†m ƒë·ªÉ t·∫£i video\n",
    "    download_from_gdrive(video_url, video_output)\n",
    "    \n",
    "    # V√≠ d·ª• t·∫£i file transcription (b·∫°n ch·ªâ c·∫ßn thay URL v√† t√™n file output)\n",
    "    # transcription_url = \\\"https://drive.google.com/file/d/ID_CUA_FILE_TRANSCRIPTION/view\\\"\n",
    "    # transcription_output = \\\"downloads/my_transcription.txt\\\"\n",
    "    # download_from_gdrive(transcription_url, transcription_output)\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ac8b1-a66d-4cda-b746-8825be1b5324",
   "metadata": {},
   "source": [
    "# Tu file MP4 tu xuat Audio wav + srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85accc-5e5b-4007-8c82-e9cfc68404fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install moviepy vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19766fb2-79a3-4700-ae13-66c3fae2109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from moviepy import VideoFileClip\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi video MP4\n",
    "video_path = r\\\"D:\\\\Documents\\\\Downloads\\\\AI-PBIRS\\\\OnTonix\\\\Stress Test first meeting with CMC-20251210_150408-Meeting Recording 1.mp4\\\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·∫°m ƒë·ªÉ l∆∞u audio WAV\n",
    "audio_path = r\\\"D:\\\\Documents\\\\Downloads\\\\AI-PBIRS\\\\OnTonix\\\\Stress Test first meeting with CMC-20251210_150408-Meeting Recording 1.wav\\\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh Vosk ti·∫øng Vi·ªát ƒë√£ gi·∫£i n√©n\n",
    "vosk_model_path = r\\\"c:\\\\vosk\\\\vosk-model-small-vn-0.4\\\"\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file ph·ª• ƒë·ªÅ SRT\n",
    "srt_output_path = r\\\"D:\\\\Documents\\\\Downloads\\\\AI-PBIRS\\\\OnTonix\\\\Stress Test first meeting with CMC-20251210_150408-Meeting Recording 1.srt\\\"\n",
    "\n",
    "# B∆∞·ªõc 1: T√°ch audio t·ª´ video v√† l∆∞u th√†nh WAV mono 16kHz\n",
    "video = VideoFileClip(video_path)\n",
    "video.audio.write_audiofile(audio_path, fps=16000, codec='pcm_s16le')\n",
    "\n",
    "# B∆∞·ªõc 2: Load m√¥ h√¨nh Vosk\n",
    "model = Model(vosk_model_path)\n",
    "\n",
    "# B∆∞·ªõc 3: M·ªü file audio WAV\n",
    "wf = wave.open(audio_path, \\\"rb\\\")\n",
    "recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "recognizer.SetWords(True)\n",
    "\n",
    "# B∆∞·ªõc 4: Nh·∫≠n d·∫°ng gi·ªçng n√≥i v√† l∆∞u c√°c ƒëo·∫°n c√≥ th·ªùi gian\n",
    "results = []\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = json.loads(recognizer.Result())\n",
    "        results.append(result)\n",
    "# L·∫•y k·∫øt qu·∫£ cu·ªëi c√πng\n",
    "final_result = json.loads(recognizer.FinalResult())\n",
    "results.append(final_result)\n",
    "\n",
    "# B∆∞·ªõc 5: Chuy·ªÉn k·∫øt qu·∫£ th√†nh ƒë·ªãnh d·∫°ng SRT\n",
    "def format_timestamp(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\\\"{h:02}:{m:02}:{s:02},{ms:03}\\\"\n",
    "\n",
    "segments = []\n",
    "index = 1\n",
    "for res in results:\n",
    "    if \\\"result\\\" in res:\n",
    "        words = res[\\\"result\\\"]\n",
    "        if words:\n",
    "            start = words[0][\\\"start\\\"]\n",
    "            end = words[-1][\\\"end\\\"]\n",
    "            text = \\\" \\\".join([w[\\\"word\\\"] for w in words])\n",
    "            segments.append((index, start, end, text))\n",
    "            index += 1\n",
    "\n",
    "# B∆∞·ªõc 6: Ghi file SRT\n",
    "with open(srt_output_path, \\\"w\\\", encoding=\\\"utf-8\\\") as srt_file:\n",
    "    for seg in segments:\n",
    "        i, start, end, text = seg\n",
    "        srt_file.write(f\\\"{i}\\\\n{format_timestamp(start)} --> {format_timestamp(end)}\\\\n{text}\\\\n\\\\n\\\")\n",
    "\n",
    "# B∆∞·ªõc 7: X√≥a file audio t·∫°m\n",
    "wf.close()\n",
    "os.remove(audio_path)\n",
    "\n",
    "print(f\\\"‚úÖ Ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {srt_output_path}\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315eada-b6c5-486c-8775-d2edf93a4618",
   "metadata": {},
   "source": [
    "# vSphere ICM [V8x] - Cecom: Download video, transcription from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31f2aa-d901-4230-a6cd-b16866d3d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip install gdown moviepy vosk wave  moviepy.editor\n",
    "!pip install gdown moviepy vosk wave  moviepy.editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a7422-82f3-48ff-bd77-8578a5d2bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "def download_from_gdrive(url, output_path):\n",
    "    \\\"\\\"\\\"\n",
    "    T·∫£i m·ªôt file t·ª´ Google Drive URL v·ªÅ ƒë∆∞·ªùng d·∫´n c·ª•c b·ªô ƒë√£ ch·ªâ ƒë·ªãnh.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL c·ªßa file tr√™n Google Drive (c·∫£ d·∫°ng view v√† share).\n",
    "        output_path (str): ƒê∆∞·ªùng d·∫´n v√† t√™n file ƒë·ªÉ l∆∞u v·ªÅ m√°y.\n",
    "    \\\"\\\"\\\"\n",
    "    try:\n",
    "        print(f\\\"ƒêang b·∫Øt ƒë·∫ßu t·∫£i t·ª´: {url}\\\")\n",
    "        print(f\\\"L∆∞u file t·∫°i: {output_path}\\\")\n",
    "        \n",
    "        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # D√πng gdown ƒë·ªÉ t·∫£i file\n",
    "        # quiet=False ƒë·ªÉ hi·ªÉn th·ªã ti·∫øn tr√¨nh t·∫£i\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "        \n",
    "        print(\\\"\\\\nT·∫£i file th√†nh c√¥ng!\\\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\\\"\\\\nƒê√£ x·∫£y ra l·ªói: {e}\\\")\n",
    "        return False\n",
    "\n",
    "# --- PH·∫¶N CH√çNH ƒê·ªÇ B·∫†N CH·∫†Y ---\n",
    "if __name__ == \\\"__main__\\\":\n",
    "    # URL c·ªßa video MP4 c·ªßa b·∫°n\n",
    "    #video_url = \\\"https://drive.google.com/file/d/17eLum7L4nd6aU4WIRAKssexcBwTzb1_x/view\\\"\n",
    "    video_url = \\\"https://drive.google.com/file/d/1-bLSmUuXM78oBT0ee0SO5cfFweHcLQRq/view?t=8612\\\"\n",
    "    #transcription_url = \\\"https://drive.google.com/file/d/1-bLSmUuXM78oBT0ee0SO5cfFweHcLQRq/view\\\"\n",
    "    video_output = \\\"D:\\\\\\\\Documents\\\\\\\\Downloads\\\\\\\\vSICM8\\\\\\\\video_cecomtech_vnpt-e\\\\\\\\ICM8x_20-11-2025.mp4\\\"\n",
    "    #transcription_output = \\\"D:\\\\\\\\Documents\\\\\\\\Downloads\\\\\\\\vSICM8\\\\\\\\video_cecomtech_vnpt-e\\\\\\\\ICM8x_20-11-2025.txt\\\"\n",
    "    \n",
    "    # G·ªçi h√†m ƒë·ªÉ t·∫£i video\n",
    "    download_from_gdrive(video_url, video_output)\n",
    "    \n",
    "    # V√≠ d·ª• t·∫£i file transcription (b·∫°n ch·ªâ c·∫ßn thay URL v√† t√™n file output)\n",
    "    # transcription_url = \\\"https://drive.google.com/file/d/ID_CUA_FILE_TRANSCRIPTION/view\\\"\n",
    "    # transcription_output = \\\"downloads/my_transcription.txt\\\"\n",
    "    # download_from_gdrive(transcription_url, transcription_output)\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb44b34-fcac-405d-9d07-32727e1f9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "from moviepy.editor import VideoFileClip\n",
    "import vosk\n",
    "import json\n",
    "import wave\n",
    "import subprocess\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# Link Google Drive File (Kh√¥ng c·∫ßn login)\n",
    "# Link b·∫°n cung c·∫•p: https://drive.google.com/file/d/1-bLSmUuXM78oBT0ee0SO5cfFweHcLQRq/view?t=8612\n",
    "file_id = '1-bLSmUuXM78oBT0ee0SO5cfFweHcLQRq'\n",
    "url_drive = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "output_video = 'ICM8x_20-11-2025.mp4'\n",
    "output_audio = 'ICM8x_20-11-2025.wav'\n",
    "output_srt = 'ICM8x_20-11-2025.srt'\n",
    "\n",
    "# 1. DOWNLOAD VIDEO B·∫∞NG GDOWN\n",
    "print(\\\"ƒêang t·∫£i video t·ª´ Google Drive...\\\")\n",
    "try:\n",
    "    gdown.download(url_drive, output_video, quiet=False)\n",
    "    print(\\\"T·∫£i video ho√†n t·∫•t!\\\")\n",
    "except Exception as e:\n",
    "    print(f\\\"L·ªói khi t·∫£i video: {e}\\\")\n",
    "\n",
    "# 2. T√ÅCH AUDIO B·∫∞NG MOVIEPY\n",
    "# Vosk y√™u c·∫ßu file audio th∆∞·ªùng l√† WAV mono 16kHz ho·∫∑c 8kHz\n",
    "print(\\\"ƒêang t√°ch audio t·ª´ video...\\\")\n",
    "if os.path.exists(output_video):\n",
    "    try:\n",
    "        # ƒê·ª£i file video t·∫£i xong m·ªõi x·ª≠ l√Ω\n",
    "        clip = VideoFileClip(output_video)\n",
    "        # L∆∞u audio d∆∞·ªõi d·∫°ng wav (codec pcm_s16le)\n",
    "        clip.audio.write_audiofile(output_audio, codec='pcm_s16le', fps=16000)\n",
    "        clip.close()\n",
    "        print(f\\\"ƒê√£ t√°ch audio th√†nh c√¥ng: {output_audio}\\\")\n",
    "    except Exception as e:\n",
    "        print(f\\\"L·ªói khi t√°ch audio: {e}\\\")\n",
    "else:\n",
    "    print(\\\"Kh√¥ng t√¨m th·∫•y file video ƒë·ªÉ t√°ch audio.\\\")\n",
    "\n",
    "# 3. T·∫†O SRT T·ª™ AUDIO B·∫∞NG VOSK (Speech-to-Text)\n",
    "# C·∫¢NH B√ÅO: B·∫°n c·∫ßn t·∫£i model Vosk v·ªÅ tr∆∞·ªõc.\n",
    "# V√≠ d·ª• v·ªõi ti·∫øng Vi·ªát: https://alphacephei.com/vosk/models\n",
    "# Gi·∫£ s·ª≠ b·∫°n ƒë√£ t·∫£i model v√† gi·∫£i n√©n v√†o th∆∞ m·ª•c hi·ªán t·∫°i t√™n l√† \\\"model_vosk\\\"\n",
    "model_path = \\\"model_vosk\\\" \n",
    "\n",
    "# Ki·ªÉm tra xem ƒë√£ t·∫£i model ch∆∞a, n·∫øu ch∆∞a th√¨ h∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng\n",
    "if not os.path.exists(model_path):\n",
    "    print(\\\"\\\\n\\\" + \\\"=\\\"*50)\n",
    "    print(\\\"THI·∫æU MODEL VOSK!\\\")\n",
    "    print(f\\\"H√£y t·∫£i model ti·∫øng Vi·ªát t·∫°i: https://alphacephei.com/vosk/models\\\")\n",
    "    print(f\\\"Gi·∫£i n√©n v√† ƒë·ªïi t√™n th∆∞ m·ª•c th√†nh: '{model_path}' r·ªìi ƒë·∫∑t c√πng file code n√†y.\\\")\n",
    "    print(\\\"=\\\"*50 + \\\"\\\\n\\\")\n",
    "else:\n",
    "    print(\\\"ƒêang chuy·ªÉn √¢m thanh th√†nh vƒÉn b·∫£n (SRT)...\\\")\n",
    "\n",
    "    # M·ªü file audio\n",
    "    wf = wave.open(output_audio, \\\"rb\\\")\n",
    "    \n",
    "    # Ki·ªÉm tra audio c√≥ ph·∫£i mono 16kHz kh√¥ng (ƒë√¢y l√† y√™u c·∫ßu c·ªßa Vosk)\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000:\n",
    "        print(\\\"C·∫£nh b√°o: File audio kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng (Mono, 16kHz). MoviePy ƒë√£ c·∫•u h√¨nh ·ªü tr√™n nh∆∞ng h√£y ki·ªÉm tra l·∫°i.\\\")\n",
    "        # N·∫øu l·ªói, b·∫°n c√≥ th·ªÉ d√πng ffmpeg ƒë·ªÉ convert th·ªß c√¥ng:\n",
    "        # !ffmpeg -i audio_extract.wav -acodec pcm_s16le -ac 1 -ar 16000 audio_fixed.wav\n",
    "    else:\n",
    "        model = vosk.Model(model_path)\n",
    "        rec = vosk.KaldiRecognizer(model, wf.getframerate())\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if rec.AcceptWaveform(data):\n",
    "                results.append(json.loads(rec.Result()))\n",
    "        \n",
    "        # L·∫•y ph·∫ßn k·∫øt qu·∫£ cu·ªëi c√πng\n",
    "        results.append(json.loads(rec.FinalResult()))\n",
    "        \n",
    "        wf.close()\n",
    "\n",
    "        # 4. GHI D·ªÆ LI·ªÜU RA FILE SRT\n",
    "        def write_srt(results, filename):\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                count = 1\n",
    "                for res in results:\n",
    "                    if 'result' in res and len(res['result']) > 0:\n",
    "                        word_list = res['result']\n",
    "                        if not word_list:\n",
    "                            continue\n",
    "                            \n",
    "                        # Th·ªùi gian b·∫Øt ƒë·∫ßu c·ªßa ƒëo·∫°n ƒë·∫ßu ti√™n\n",
    "                        start_time = word_list[0]['start']\n",
    "                        # Th·ªùi gian k·∫øt th√∫c c·ªßa ƒëo·∫°n cu·ªëi c√πng\n",
    "                        end_time = word_list[-1]['end']\n",
    "                        \n",
    "                        # Gh√©p c√°c t·ª´ th√†nh c√¢u\n",
    "                        text = ' '.join([w['word'] for w in word_list])\n",
    "                        \n",
    "                        # Format th·ªùi gian SRT: 00:00:00,000\n",
    "                        start_srt = format_time(start_time)\n",
    "                        end_srt = format_time(end_time)\n",
    "                        \n",
    "                        f.write(f\\\"{count}\\\\n{start_srt} --> {end_srt}\\\\n{text}\\\\n\\\\n\\\")\n",
    "                        count += 1\n",
    "        \n",
    "        def format_time(seconds):\n",
    "            hours = int(seconds // 3600)\n",
    "            minutes = int((seconds % 3600) // 60)\n",
    "            secs = int(seconds % 60)\n",
    "            millis = int((seconds - int(seconds)) * 1000)\n",
    "            return f\\\"{hours:02}:{minutes:02}:{secs:02},{millis:03}\\\"\n",
    "\n",
    "        write_srt(results, output_srt)\n",
    "        print(f\\\"ƒê√£ t·∫°o file ph·ª• ƒë·ªÅ: {output_srt}\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbd440-cc8a-4a09-b70e-81f5ab2ed78d",
   "metadata": {},
   "source": [
    "# D√πng c√°ch g√¨ ƒë·ªÉ ph√¢n t√≠ch Youtube clip v√† x√°c ƒë·ªãnh AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3a3cd-0d7e-47b6-b42f-2a7b1f0b49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip install google-generativeai \\\"c≈© end of support pandas markdown genai google.genai\"\n",
    "!pip install pandas markdown genai google.genai\n",
    "!pip install --upgrade pip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bfdba-6a03-41d1-89cd-1a8578d2d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.genai as genai  # ƒê√∫ng c√°ch 1\n",
    "\n",
    "# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env\n",
    "load_dotenv()\n",
    "\n",
    "# L·∫•y gi√° tr·ªã c·ªßa bi·∫øn m√¥i tr∆∞·ªùng GOOGLE_API_KEY\n",
    "google_api_key = os.getenv(\\\"GOOGLE_API_KEY\\\")\n",
    "\n",
    "# Ki·ªÉm tra xem bi·∫øn m√¥i tr∆∞·ªùng c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "if google_api_key is None:\n",
    "    raise ValueError(\\\"GOOGLE_API_KEY not found in environment variables or .env file.\\\")\n",
    "\n",
    "# S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ kh·ªüi t·∫°o client\n",
    "client = genai.Client(api_key=google_api_key)\n",
    "response = client.models.generate_content(\n",
    "    model=\\\"gemini-2.5-flash\\\", contents=\\\"\\\"\\\"\n",
    "T√¥i c√≥ link youtube: https://youtu.be/Z05MgddCeUo?si=vB0FL8Hynq2EK0O8\n",
    "H√£y ph√¢n t√≠ch ch√≠nh x√°c, c·ª• th·ªÉ ƒë·ªÉ x√°c ƒë·ªãnh clip tr√™n Youtube ki·ªÉu n√†y ƒë∆∞·ª£c d·ª±ng t·ª´ AI n√†o ?\n",
    "t√¥i c√≥ tham kh·∫£o https://cafef.vn/cach-nhan-biet-video-that-hay-do-ai-tao-188251027073116263.chn, https://hocvienmarketingonline.com/cach-nhan-biet-video-do-ai-tao v√† c√≥ th·ªÉ d√πng: https://verify.contentauthenticity.org/ import file mp4 ƒë√£ download t·ª´ youtube tr√™n? \n",
    "    \\\"\\\"\\\"\n",
    ")\n",
    "print(response.text)\n",
    "# N·∫øu b·∫°n vi·∫øt r·∫±ng \\\"Xin l∆∞u √Ω r·∫±ng v√¨ t√¥i kh√¥ng c√≥ n·ªôi dung file SRT th·ª±c t·∫ø, c√°c ph√¢n t√≠ch d∆∞·ªõi ƒë√¢y \n",
    "# s·∫Ω d·ª±a tr√™n th√¥ng tin t·ª´ ti√™u ƒë·ªÅ, \n",
    "# ki·∫øn th·ª©c chung v·ªÅ ch·ªß ƒë·ªÅ n√†y v√† nh·ªØng n·ªôi dung th∆∞·ªùng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong c√°c video t∆∞∆°ng t·ª±.\\\"\n",
    "# th√¨ c√≥ c√°ch n√†o b·∫°n h√£y ch·ªâ cho t√¥i c·ª• th·ªÉ ƒë·ªÅ  b·∫°n c√≥ th·ªÉ ti·∫øp c·∫≠n n·ªôi dung file srt n√†y ? \n",
    "# v√≠ d·ª• vi·∫øt code python ? upload file ??\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e396328-6f4c-4546-852d-dc39a8e5dac1",
   "metadata": {},
   "source": [
    "# Download Youtube t·ª´ m·ª•c ti√™u Edu training show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7294bd6-b759-4bc4-b265-ad4d015d34cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: c:\\Users\\thang\\AppData\\Local\\Temp\\tmp3aw0lcji\n",
      "Requirement already satisfied: setuptools in c:\\python311\\mega6b45\\lib\\site-packages (65.5.0)\n",
      "Requirement already satisfied: pip in c:\\python311\\mega6b45\\lib\\site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp\n",
    "import sys\n",
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán b·∫±ng c√°ch g·ªçi ƒë√∫ng python executable hi·ªán t·∫°i\n",
    "!{sys.executable} -m pip install yt-dlp\n",
    "import sys\n",
    "# C√†i ƒë·∫∑t l·∫°i pip cho phi√™n b·∫£n python hi·ªán t·∫°i\n",
    "!{sys.executable} -m ensurepip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d5d92-2d89-4d6f-bc88-0f992faa4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "# --- C·∫§U H√åNH TH∆Ø M·ª§C ---\n",
    "# S·ª≠ d·ª•ng raw string (r'') ƒë·ªÉ tr√°nh l·ªói k√Ω t·ª± escape trong ƒë∆∞·ªùng d·∫´n\n",
    "download_dir = r'c:\\\\python311\\\\ytb-api\\\\videoytb'\n",
    "\n",
    "# Ki·ªÉm tra v√† t·∫°o th∆∞ m·ª•c (Y√™u c·∫ßu ch·∫°y quy·ªÅn Admin)\n",
    "try:\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    print(f\\\"ƒê√£ s·∫µn s√†ng l∆∞u file v√†o: {download_dir}\\\")\n",
    "except PermissionError:\n",
    "    print(\\\"L·ªñI: B·∫°n kh√¥ng c√≥ quy·ªÅn ghi v√†o th∆∞ m·ª•c n√†y.\\\")\n",
    "    print(\\\"Gi·∫£i ph√°p: H√£y t·∫Øt Jupyter, nh·∫•n chu·ªôt ph·∫£i v√†o icon Jupyter -> Ch·ªçn 'Run as Administrator'.\\\")\n",
    "    # D·ª´ng ch∆∞∆°ng tr√¨nh n·∫øu kh√¥ng c√≥ quy·ªÅn\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# URL video\n",
    "video_url = \\\"https://vcf.broadcom.com/tools/vsansizer/assets/video/vsanesa-getstarted.mp4\\\"\n",
    "\n",
    "# --- C·∫§U H√åNH YT-DLP ---\n",
    "ydl_opts = {\n",
    "    # 1. Ch·ªçn format video t·ªët nh·∫•t v√† audio t·ªët nh·∫•t, ∆∞u ti√™n mp4 ƒë·ªÉ merge d·ªÖ d√†ng\n",
    "    #    N·∫øu c√≥ s·∫µn file mp4 ƒë·ªôc l·∫≠p th√¨ l·∫•y, kh√¥ng th√¨ t·∫£i video + audio ri√™ng r·ªìi g·ªôp\n",
    "    'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
    "    \n",
    "    # 2. ƒê∆∞·ªùng d·∫´n l∆∞u file\n",
    "    'outtmpl': os.path.join(download_dir, '%(title)s.%(ext)s'),\n",
    "    \n",
    "    # 3. C·∫•u h√¨nh ph·ª• ƒë·ªÅ: Ch·ªâ ti·∫øng Anh (en)\n",
    "    'writesubtitles': True,             # B·∫≠t t·∫£i ph·ª• ƒë·ªÅ\n",
    "    'writeautomaticsub': True,          # B·∫≠t ph·ª• ƒë·ªÅ t·ª± ƒë·ªông n·∫øu kh√¥ng c√≥ ph·ª• ƒë·ªÅ g·ªëc\n",
    "    'subtitleslangs': ['en'],           # Ch·ªâ l·∫•y list ['en']\n",
    "    'subtitlesformat': 'srt',           # ƒê·ªãnh d·∫°ng ph·ª• ƒë·ªÅ\n",
    "    \n",
    "    # 4. ƒê·ªãnh d·∫°ng ƒë·∫ßu ra sau khi merge\n",
    "    'merge_output_format': 'mp4',\n",
    "    \n",
    "    # 5. D·ªçn d·∫πp\n",
    "    'keepvideo': False,                 # False = X√≥a file video/audio r·ªùi r·∫°c sau khi ƒë√£ merge th√†nh MP4 xong\n",
    "    'quiet': False,                     # Hi·ªán th·ªã log qu√° tr√¨nh t·∫£i\n",
    "    'no_warnings': False\n",
    "}\n",
    "\n",
    "# --- CH·∫†Y T·∫¢I ---\n",
    "try:\n",
    "    print(f\\\"ƒêang b·∫Øt ƒë·∫ßu t·∫£i: {video_url}\\\")\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "    print(\\\"\\\\nHO√ÄN T·∫§T!\\\")\n",
    "    print(f\\\"File MP4 v√† ph·ª• ƒë·ªÅ .srt ƒë√£ l∆∞u t·∫°i: {download_dir}\\\")\n",
    "except Exception as e:\n",
    "    print(f\\\"\\\\nƒê√£ x·∫£y ra l·ªói: {e}\\\")\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1fa7e-b016-4417-9ec0-30ffaf4592ba",
   "metadata": {},
   "source": [
    "# H√†m d·ªãch t·ª´ local th∆∞ m·ª•c nhi·ªÅu file mp4 sang c√≥ ph·ª• ƒë·ªÅ srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488aecfd-8c72-4fe6-804d-e7737105efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper\n",
    "import whisper\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a video c·ªßa b·∫°n\n",
    "VIDEO_DIR = r\\\"c:\\\\python311\\\\ytb-api\\\\videoytb\\\"\n",
    "\n",
    "# Ch·ªçn model AI: 'tiny', 'base', 'small', 'medium', 'large'\n",
    "# 'base' l√† c√¢n b·∫±ng nh·∫•t gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c cho ti·∫øng Anh.\n",
    "# N·∫øu video ti·∫øng Vi·ªát, n√™n d√πng 'medium' ho·∫∑c 'large' ƒë·ªÉ ch√≠nh x√°c h∆°n, nh∆∞ng s·∫Ω ch·∫≠m h∆°n.\n",
    "MODEL_SIZE = \\\"base\\\" \n",
    "\n",
    "def format_timestamp(seconds: float):\n",
    "    \\\"\\\"\\\"H√†m chuy·ªÉn ƒë·ªïi gi√¢y sang ƒë·ªãnh d·∫°ng th·ªùi gian SRT (00:00:00,000)\\\"\\\"\\\"\n",
    "    td = timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = int((td.total_seconds() - total_seconds) * 1000)\n",
    "    return f\\\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\\\"\n",
    "\n",
    "def generate_srt_file(video_path, model_size=\\\"base\\\"):\n",
    "    \\\"\\\"\\\"H√†m t·∫£i video, ch·∫°y AI v√† l∆∞u file SRT\\\"\\\"\\\"\n",
    "    \n",
    "    print(f\\\"ƒêang x·ª≠ l√Ω: {os.path.basename(video_path)}...\\\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Load model Whisper\n",
    "        # fp16=False gi√∫p tr√°nh l·ªói tr√™n m·ªôt s·ªë m√°y t√≠nh Windows kh√¥ng h·ªó tr·ª£ GPU t·ªët\n",
    "        model = whisper.load_model(model_size)\n",
    "        \n",
    "        # 2. Chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n\n",
    "        # language='vi' n·∫øu b·∫°n ch·∫Øc ch·∫Øn video ti·∫øng Vi·ªát (ch√≠nh x√°c h∆°n).\n",
    "        # N·∫øu b·ªè qua language, n√≥ s·∫Ω t·ª± nh·∫≠n di·ªán.\n",
    "        result = model.transcribe(video_path, fp16=False) \n",
    "        \n",
    "        # 3. T·∫°o n·ªôi dung file SRT\n",
    "        srt_content = []\n",
    "        for i, segment in enumerate(result['segments']):\n",
    "            start_time = format_timestamp(segment['start'])\n",
    "            end_time = format_timestamp(segment['end'])\n",
    "            text = segment['text'].strip()\n",
    "            \n",
    "            srt_entry = f\\\"{i + 1}\\\\n{start_time} --> {end_time}\\\\n{text}\\\\n\\\\n\\\"\n",
    "            srt_content.append(srt_entry)\n",
    "            \n",
    "        # 4. L∆∞u file SRT\n",
    "        srt_path = os.path.splitext(video_path)[0] + \\\".srt\\\"\n",
    "        with open(srt_path, \\\"w\\\", encoding=\\\"utf-8\\\") as f:\n",
    "            f.writelines(srt_content)\n",
    "            \n",
    "        print(f\\\"ƒê√£ t·∫°o ph·ª• ƒë·ªÅ th√†nh c√¥ng: {srt_path}\\\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\\\"L·ªói khi x·ª≠ l√Ω {os.path.basename(video_path)}: {e}\\\")\n",
    "\n",
    "# --- CH∆Ø∆†NG TR√åNH CH√çNH ---\n",
    "if __name__ == \\\"__main__\\\":\n",
    "    # Ki·ªÉm tra xem th∆∞ m·ª•c c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "    if not os.path.exists(VIDEO_DIR):\n",
    "        print(f\\\"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {VIDEO_DIR}\\\")\n",
    "    else:\n",
    "        # L·∫•y danh s√°ch t·∫•t c·∫£ file mp4 trong th∆∞ m·ª•c\n",
    "        files = [f for f in os.listdir(VIDEO_DIR) if f.endswith(\\\".mp4\\\")]\n",
    "        \n",
    "        if not files:\n",
    "            print(\\\"Kh√¥ng t√¨m th·∫•y file .mp4 n√†o trong th∆∞ m·ª•c.\\\")\n",
    "        else:\n",
    "            print(f\\\"T√¨m th·∫•y {len(files)} video. B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ...\\\\n\\\")\n",
    "            for file in files:\n",
    "                full_path = os.path.join(VIDEO_DIR, file)\n",
    "                generate_srt_file(full_path, MODEL_SIZE)\n",
    "            \n",
    "            print(\\\"\\\\nHo√†n t·∫•t!\\\")\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be54fb-cd72-486e-87d7-f08b2073be69",
   "metadata": {},
   "source": [
    "# H√†m d·ªãch t·ª´ 1 file local mp4 sang file ph·ª• ƒë·ªÅ srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140d7766-ae5a-4049-903c-a0c59bb37c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang b·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: vsanesa-getstarted.mp4...\n",
      "ƒêang t·∫£i model AI: base (L·∫ßn ƒë·∫ßu s·∫Ω t·∫£i model v·ªÅ, c√°c l·∫ßn sau s·∫Ω nhanh h∆°n)\n",
      "ƒê√£ chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i xong. ƒêang ƒë·ªãnh d·∫°ng file SRT...\n",
      "--- TH√ÄNH C√îNG ---\n",
      "File ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: c:\\python311\\ytb-api\\videoytb\\vsanesa-getstarted.srt\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---\n",
    "# ƒê∆∞·ªùng d·∫´n file video c·ª• th·ªÉ c·ªßa b·∫°n\n",
    "VIDEO_PATH = r\"c:\\python311\\ytb-api\\videoytb\\vsanesa-getstarted.mp4\"\n",
    "\n",
    "# Ch·ªçn model AI: 'tiny', 'base', 'small', 'medium', 'large'\n",
    "# N√™n d√πng 'medium' ho·∫∑c 'large' n·∫øu video ti·∫øng Vi·ªát ƒë·ªÉ ƒë·ªô ch√≠nh x√°c cao h∆°n.\n",
    "MODEL_SIZE = \"base\" \n",
    "\n",
    "def format_timestamp(seconds: float):\n",
    "\"\"H√†m chuy·ªÉn ƒë·ªïi gi√¢y sang ƒë·ªãnh d·∫°ng th·ªùi gian SRT (00:00:00,000)\"\"\"\n",
    "    td = timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = int((td.total_seconds() - total_seconds) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
    "\n",
    "def generate_srt_for_single_file(video_file, model_size=\"base\"):\n",
    "    # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "    if not os.path.exists(video_file):\n",
    "        print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file video t·∫°i ƒë∆∞·ªùng d·∫´n: {video_file}\")\n",
    "        return\n",
    "\n",
    "    print(f\"ƒêang b·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {os.path.basename(video_file)}...\")\n",
    "    print(f\"ƒêang t·∫£i model AI: {model_size} (L·∫ßn ƒë·∫ßu s·∫Ω t·∫£i model v·ªÅ, c√°c l·∫ßn sau s·∫Ω nhanh h∆°n)\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Load model Whisper\n",
    "        # fp16=False ƒë·ªÉ ch·∫°y ·ªïn ƒë·ªãnh h∆°n tr√™n m√°y t√≠nh d√πng CPU\n",
    "        model = whisper.load_model(model_size)\n",
    "        \n",
    "        # 2. Chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n\n",
    "        # N·∫øu video ti·∫øng Vi·ªát, h√£y th√™m: language='vi'\n",
    "        result = model.transcribe(video_file, fp16=False)\n",
    "        \n",
    "        print(\"ƒê√£ chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i xong. ƒêang ƒë·ªãnh d·∫°ng file SRT...\")\n",
    "        \n",
    "        # 3. T·∫°o n·ªôi dung file SRT\n",
    "        srt_content = []\n",
    "        for i, segment in enumerate(result['segments']):\n",
    "            start_time = format_timestamp(segment['start'])\n",
    "            end_time = format_timestamp(segment['end'])\n",
    "            text = segment['text'].strip()\n",
    "            \n",
    "            srt_entry = f\"{i + 1}\\n{start_time} --> {end_time}\\n{text}\\n\\n\"\n",
    "            srt_content.append(srt_entry)\n",
    "            \n",
    "        # 4. L∆∞u file SRT (c√πng th∆∞ m·ª•c v√† t√™n v·ªõi file video c≈©)\n",
    "        base_name = os.path.splitext(video_file)[0]\n",
    "        srt_path = base_name + \".srt\"\n",
    "        \n",
    "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(srt_content)\n",
    "            \n",
    "        print(f\"--- TH√ÄNH C√îNG ---\")\n",
    "        print(f\"File ph·ª• ƒë·ªÅ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {srt_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω: {e}\")\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "if __name__ == \"__main__\":\n",
    "    generate_srt_for_single_file(VIDEO_PATH, MODEL_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61aaad-0866-4d9b-af4c-9b2d9987bf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
